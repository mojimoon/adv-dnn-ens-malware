from learner import model_scope_dict
from tools import utils
import numpy as np
'''
Perform retraining with the candidate set selected with test selection metrics
'''

import sys
import logging
import os
import csv
from config import config

logger = logging.getLogger(__name__)
logger.setLevel(level=logging.DEBUG)
# StreamHandler
stream_handler = logging.StreamHandler(sys.stdout)
stream_handler.setLevel(level=logging.DEBUG)
logger.addHandler(stream_handler)
# FileHandler
file_handler = logging.FileHandler('retrain_selected.log')
file_handler.setLevel(level=logging.INFO)
formatter = logging.Formatter('%(asctime)s - %(message)s')
file_handler.setFormatter(formatter)
logger.addHandler(file_handler)

# begin config

tests = [
    # {
    #     'selection_metric': ['random', 'gd', 'entropy', 'deepgini', 'dat'],
    #     'budget': [0.05, 0.1, 0.2, 0.3],
    #     'id_ratio': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
    #     'method': ['fgsm', 'GDKDE', 'MIMICRY', 'POINTWISE']
    # },
    # {
    #     'selection_metric': ['random', 'gd', 'entropy', 'deepgini'],
    #     'budget': [0.05, 0.1, 0.2, 0.3],
    #     'id_ratio': [1.0],
    #     'method': ['fgsm', 'GDKDE', 'MIMICRY', 'POINTWISE']
    # },
    # {
    #     'selection_metric': ['none'],
    #     'budget': [1.0],
    #     'id_ratio': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
    #     'method': ['fgsm', 'GDKDE', 'MIMICRY', 'POINTWISE']
    # }
    {
        'selection_metric': ['dat_ood_detector', 'ensemble_ood_detector'],
        'budget': [0.05, 0.1, 0.2, 0.3],
        'id_ratio': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
        'method': ['fgsm', 'GDKDE', 'MIMICRY', 'POINTWISE']
    }
]

model_name = 'deepdrebin'
retrain_type = 'type1'
test_set = 'hybrid'

# end config

TYPE1 = 'type1'
TYPE2 = 'type2'
HYBRID = 'hybrid'
ORIGINAL = 'original'
DEEPDREBIN = 'deepdrebin'
BASIC_DNN = 'basic_dnn'

targeted_model_names_dict = model_scope_dict.copy()
targeted_model_name = 'basic_dnn'
targeted_model = targeted_model_names_dict[targeted_model_name](mode='test')

project_root = config.get('DEFAULT', 'project_root')
dataset_root = config.get('dataset', 'dataset_root')
feat_path = dataset_root
if model_name == DEEPDREBIN:
    feat_path = os.path.join(feat_path, 'attack', 'adversarial_samples')
else:
    feat_path = os.path.join(feat_path, 'attack_b_dnn', 'adversarial_samples')

log_path = os.path.join(project_root, 'results', 'retrain', 'retrain_{}_{}_{}.csv'.format(model_name, retrain_type, test_set))

# Note that pristine feats are the same under each attack methods.
pristine_feat_path = os.path.join(feat_path, 'fgsm', 'pristine_l-infinity.data')
pristine_feat = utils.readdata_np(pristine_feat_path)

#todo: change to other attack methods's perturbed feat path
all_methods = ['fgsm', 'PGD-linf', 'PGD-l2', 'PGD-l1', 'PGD-Adam', 'GDKDE', 'BCA_K', 'BGA_K', 'GROSSE', 'JSMA', 'MAX', 'MIMICRY', 'POINTWISE']
all_perturbed_paths = [
    os.path.join(feat_path, 'fgsm', 'fgsm_l-infinity.data'),
    os.path.join(feat_path, 'pgdlinf', 'pgdlinf_l-infinity.data'),
    os.path.join(feat_path, 'pgdl2', 'pgdl2_l2.data'),
    os.path.join(feat_path, 'pgdl1', 'pgdl1_.data'),
    os.path.join(feat_path, 'pgd_adam', 'pgd_adam_.data'),
    os.path.join(feat_path, 'gdkde', 'gdkde_.data'),
    os.path.join(feat_path, 'bca_k', 'bca_k_.data'),
    os.path.join(feat_path, 'bga_k', 'bga_k_.data'),
    os.path.join(feat_path, 'grosse', 'grosse_.data'),
    os.path.join(feat_path, 'jsma', 'jsma_.data'),
    os.path.join(feat_path, 'max', 'max_.data'),
    os.path.join(feat_path, 'mimicry', 'mimicry_.data'),
    os.path.join(feat_path, 'pointwise', 'pointwise_.data'),
]

trainX, valX, testX = utils.read_joblib(config.get('feature.drebin', 'dataX'))
trainy, valy, testy = utils.read_joblib(config.get('feature.drebin', 'datay'))

def write_to_csv(output_file, data):
    file_exists = os.path.isfile(output_file)
    with open(output_file, 'a') as csvfile:
        fieldnames = ['model', 'retrain_type', 'test_set', 'method', 'selection_metric', 'epochs', 'id_ratio', 'budget', 'original_acc', 'retrain_acc', 'acc_improvement']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        if not file_exists:
            writer.writeheader()
        writer.writerow(data)

def retrain_selected(test_params):
    selection_metric = test_params['selection_metric']
    bg = test_params['budget']
    # retrain_epochs = test_params['epochs']
    retrain_epochs = retrain_type == TYPE1 and [30] or [10]
    id_dist = test_params['id_ratio']
    methods = test_params['method']
    perturbed_paths = [all_perturbed_paths[all_methods.index(method)] for method in methods]

    for method, perturbed_path in zip(methods, perturbed_paths):
        if perturbed_path is None:
            continue
        perturbed_feat = utils.readdata_np(perturbed_path)
        for budget in bg:
            for metric in selection_metric:
                for epochs in retrain_epochs:
                    accuracies, ori_accs = [], []
                    for id_ratio in id_dist:
                        id_size = int(pristine_feat.shape[0]*id_ratio)
                        ood_size = int(pristine_feat.shape[0] - id_size)
                        id_feat = pristine_feat[:id_size]

                        # split id feat into two sets
                        candidate_set_id = id_feat[:int(id_size*0.5)]
                        test_set_id = id_feat[int(id_size*0.5):]

                        ood_feat = perturbed_feat[id_size:]
                        candidate_set_ood = ood_feat[:int(ood_size*0.5)]
                        test_set_ood = ood_feat[int(ood_size*0.5):]


                        # reconstruct hybrid test set and hybrid candidate set
                        hybrid_candidate_set = np.concatenate((candidate_set_id, candidate_set_ood), axis=0)
                        hybrid_test_set = np.concatenate((test_set_id, test_set_ood), axis=0)
                        labels = np.ones(hybrid_test_set.shape[0])
                        test_labels = np.ones(hybrid_test_set.shape[0])

                        _testX, _testy = None, None

                        if test_set == HYBRID:
                            _testX, _testy = hybrid_test_set, labels
                        else:
                            _testX, _testy = testX, testy

                        ori_acc = targeted_model.test_rpst(testX=_testX, testy=_testy, is_single_class=True)

                        retrainX, retrainy = None, None

                        if budget == 1.0:
                            if retrain_type == TYPE1:
                                retrainX, retrainy = hybrid_candidate_set, labels
                            else:
                                retrainX = np.concatenate((hybrid_candidate_set, trainX), axis=0)
                                retrainy = np.concatenate((labels, trainy), axis=0)
                        else:
                            selected_candidateX, selected_candidatey = targeted_model.selection(
                                budget=budget,
                                trainX=trainX,
                                trainy=trainy,
                                candidateX=hybrid_candidate_set,
                                candidateX_id=candidate_set_id,
                                candidatey=labels,
                                candidatey_id=np.ones(candidate_set_id.shape[0]),
                                hybrid_test=hybrid_test_set,
                                hybrid_testy=test_labels,
                                metric=metric,
                                id_ratio=id_ratio)
                            if retrain_type == TYPE1:
                                retrainX, retrainy = selected_candidateX, selected_candidatey
                            else:
                                concated_trainX = np.concatenate((selected_candidateX, trainX), axis=0)
                                concated_trainy = np.concatenate((selected_candidatey, trainy), axis=0)
                                retrainX, retrainy = concated_trainX, concated_trainy

                        acc = targeted_model.retrain(candidateX=retrainX, candidatey=retrainy, testX=_testX, testy=_testy, epochs=epochs)
                        accuracies.append(acc*100)
                        ori_accs.append(ori_acc*100)
                    for i in range(len(id_dist)):
                        write_to_csv(log_path, {'method': method, 'id_ratio': id_dist[i], 'budget': budget, 'selection_metric': metric,  'original_acc': ori_accs[i], 'retrain_acc': accuracies[i], 'acc_improvement': accuracies[i]-ori_accs[i], 'epochs': epochs, 'retrain_type': retrain_type, 'test_set': test_set, 'model': model_name})

def main():
    for test in tests:
        retrain_selected(test)

if __name__ == '__main__':
    main()