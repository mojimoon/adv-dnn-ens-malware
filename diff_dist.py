from learner import model_scope_dict
from tools import utils
import numpy as np
import config as cfg
#logging
logger = cfg.logging.getLogger("test_set_distributions_acc")
logger.addHandler(cfg.ErrorHandler)


targeted_model_names_dict = model_scope_dict.copy()
targeted_model_name = 'deepdrebin'
targeted_model = targeted_model_names_dict[targeted_model_name](mode='test')


# test on 11 different test set distributions
id_dist = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
ood_dist = [1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0.0]
# Note that pristine feats are the same under each attack methods.
pristine_feat_path = '/home/jzhang2297/anomaly/malware/adversarial-deep-ensemble-droidmawlare/drebin/drebin/attack/adversarial_samples/fgsm/pristine_l-infinity.data'
pristine_feat = utils.readdata_np(pristine_feat_path)

#todo: change to other attack methods's perturbed feat path
methods = ['fgsm', 'PGD-linf', 'PGD-l2', 'PGD-l1', 'PGD-Adam', 'GDKDE', 'BCA_K', 'BGA_K', 'GROSSE', 'JSMA', 'MAX', 'MIMICRY', 'POINTWISE']
perturbed_paths = ['/home/jzhang2297/anomaly/malware/adversarial-deep-ensemble-droidmawlare/drebin/drebin/attack/adversarial_samples/fgsm/fgsm_l-infinity.data',
                   '/home/jzhang2297/anomaly/malware/adversarial-deep-ensemble-droidmawlare/drebin/drebin/attack/adversarial_samples/pgdlinf/pgdlinf_l-infinity.data',
                   '/home/jzhang2297/anomaly/malware/adversarial-deep-ensemble-droidmawlare/drebin/drebin/attack/adversarial_samples/pgdl2/pgdl2_l2.data',
                   '/home/jzhang2297/anomaly/malware/adversarial-deep-ensemble-droidmawlare/drebin/drebin/attack/adversarial_samples/pgdl1/pgdl1_.data',
                   '/home/jzhang2297/anomaly/malware/adversarial-deep-ensemble-droidmawlare/drebin/drebin/attack/adversarial_samples/pgd_adam/pgd_adam_.data',
                   '/home/jzhang2297/anomaly/malware/adversarial-deep-ensemble-droidmawlare/drebin/drebin/attack/adversarial_samples/gdkde/gdkde_.data',
                   '/home/jzhang2297/anomaly/malware/adversarial-deep-ensemble-droidmawlare/drebin/drebin/attack/adversarial_samples/bca_k/bca_k_.data',
                   '/home/jzhang2297/anomaly/malware/adversarial-deep-ensemble-droidmawlare/drebin/drebin/attack/adversarial_samples/bga_k/bga_k_.data',
                   '/home/jzhang2297/anomaly/malware/adversarial-deep-ensemble-droidmawlare/drebin/drebin/attack/adversarial_samples/grosse/grosse_.data',
                   None, None, None, None, None]


for method, perturbed_path in zip(methods, perturbed_paths):
    import pdb; pdb.set_trace()
    perturbed_feat = utils.readdata_np(perturbed_path)
    for id_ratio in id_dist:
        id_size = int(pristine_feat.shape[0]*id_ratio)
        # reconstruct test data with different distributions
        test_data = np.concatenate((pristine_feat[:id_size], perturbed_feat[id_size:]), axis=0)
        labels = np.ones(test_data.shape[0])
        acc_pert = targeted_model.test_rpst(test_data, labels, is_single_class=True)
        print(perturbed_path)
        print("Accuracy on test set is {0}% with ID ratio {1}, ID size = {2}, attack method is {3}".format(acc_pert*100, id_ratio, id_size, method))
        logger.info("Accuracy on test set is {0}% with ID ratio {1}, ID size = {2}, attack method is {3}".format(acc_pert*100, id_ratio, id_size, method))