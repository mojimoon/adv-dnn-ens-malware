from learner import model_scope_dict
from tools import utils
import numpy as np
'''
Perform retraining with the candidate set selected with test selection metrics
OOD by out of source samples.
OOD: Drebin; ID: AndroZoo
'''

import sys
import logging
import os
import csv

logger = logging.getLogger(__name__)
logger.setLevel(level=logging.DEBUG)
# StreamHandler
stream_handler = logging.StreamHandler(sys.stdout)
stream_handler.setLevel(level=logging.DEBUG)
logger.addHandler(stream_handler)
# FileHandler
file_handler = logging.FileHandler('retrain_selected_outofsrc_andro.log')
file_handler.setLevel(level=logging.INFO)
formatter = logging.Formatter('%(asctime)s - %(message)s')
file_handler.setFormatter(formatter)
logger.addHandler(file_handler)

#todo: change to load androzoo deepdrebin path
targeted_model_names_dict = model_scope_dict.copy()
targeted_model_name = 'basic_dnn'
targeted_model = targeted_model_names_dict[targeted_model_name](mode='test')

pwd = os.getcwd()
root = os.path.dirname(pwd)
log_path = os.path.join(pwd, 'results', 'retrain_selected_outofsrc_andro.csv')

# load AndroZoo data (ID)
androX_path = '/home/jzhang2297/anomaly/malware/adversarial-deep-ensemble-droidmawlare/androzoo/derbin/X.pkl'
androy_path = '/home/jzhang2297/anomaly/malware/adversarial-deep-ensemble-droidmawlare/androzoo/derbin/y.pkl'
_, _, testX_andro = utils.read_joblib(androX_path)
_, _, testy_andro = utils.read_joblib(androy_path)

# load Drebin data (OOD)
drebinX_path = '/home/jzhang2297/anomaly/malware/adversarial-deep-ensemble-droidmawlare/drebin/drebin/X.pkl'
drebiny_path = '/home/jzhang2297/anomaly/malware/adversarial-deep-ensemble-droidmawlare/drebin/drebin/y.pkl'
_, _, testX_drebin = utils.read_joblib(drebinX_path)
_, _, testy_drebin = utils.read_joblib(drebiny_path)

# split test data into candidate & new test
size = 4000
candidate_andro_idx = np.random.choice(np.arange(len(testX_andro)), size=size, replace=False)
candidate_drebin_idx = np.random.choice(np.arange(len(testX_drebin)), size=size, replace=False)

can_andro, can_androy = testX_andro[candidate_andro_idx], testy_andro[candidate_andro_idx] # (4000,10000)
can_drebin, can_drebiny = testX_drebin[candidate_drebin_idx], testy_drebin[candidate_drebin_idx]

test_andro, test_androy = np.delete(testX_andro, candidate_andro_idx, axis=0)[:size], np.delete(testy_andro, candidate_andro_idx)[:size]
test_drebin, test_drebiny = np.delete(testX_drebin, candidate_drebin_idx, axis=0)[:size], np.delete(testy_drebin, candidate_drebin_idx)[:size]

# test on 11 different test set distributions
id_dist = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]#, 1.0]
#ood_dist = [1.0, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1]#, 0.0]

selection_metric = ['entropy', 'deepgini', 'dat']
bg = [0.01, 0.03, 0.05, 0.1, 0.2, 0.3]
retrain_epochs = [5, 10, 15, 20, 25, 30]

def write_to_csv(output_file, data):
    file_exists = os.path.isfile(output_file)
    with open(output_file, 'a') as csvfile:
        fieldnames = ['selection_metric', 'epochs', 'id_ratio', 'budget', 'original_acc', 'retrain_acc', 'acc_improvement']
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        if not file_exists:
            writer.writeheader()
        writer.writerow(data)

for metric in selection_metric:
    for budget in bg:
        for epochs in retrain_epochs:
            accuracies, ori_accs = [], []
            for id_ratio in id_dist:
                print('*************ID_ratio***********', id_ratio)
                id_size = int(can_andro.shape[0] * id_ratio)
                id_feat_can, id_y_can = can_andro[:id_size], can_androy[:id_size]
                id_feat_test, id_y_test = test_andro[:id_size], test_androy[
                                                                :id_size]  # new test set has the same dist as candidate set.

                ood_size = size - id_size
                ood_feat_can, ood_y_can = can_drebin[:ood_size], can_drebiny[:ood_size]
                ood_feat_test, ood_y_test = test_drebin[:ood_size], test_drebiny[:ood_size]

                hybrid_candidateX = np.concatenate((id_feat_can, ood_feat_can), axis=0)  # shape 4000,10000
                hybrid_candidatey = np.concatenate((id_y_can, ood_y_can), axis=0)

                hybrid_testX = np.concatenate((id_feat_test, ood_feat_test), axis=0)  # shape 4000,10000
                hybrid_testy = np.concatenate((id_y_test, ood_y_test), axis=0)

                ori_acc = targeted_model.test_rpst(testX=hybrid_testX, testy=hybrid_testy, is_single_class=True)

                selected_candidateX, selected_candidatey = targeted_model.selection(budget=budget, candidateX=hybrid_candidateX,
                                                                candidateX_id=id_feat_can, candidatey=hybrid_candidatey, candidatey_id=np.ones(id_y_can.shape[0]),
                                                                                    hybrid_test=hybrid_testX, hybrid_testy=hybrid_testy, metric=metric, id_ratio=id_ratio)
                print('############ Start Retraining #############')
                acc = targeted_model.retrain(candidateX=selected_candidateX, candidatey=selected_candidatey, testX=hybrid_testX, testy=hybrid_testy, epochs=epochs)
                accuracies.append(acc*100)
                ori_accs.append(ori_acc*100)
            # logger.info('ID ratio: {0}, Method: Out of Source'.format(id_dist))
            # logger.info('Budget = {0}, Selection metric = {1}'.format(budget, metric))
            # logger.info('Original Accuracy on hybrid test set: {0} with size {1} '.format(np.array(ori_accs), hybrid_testy.shape[0]))
            # logger.info('Retrained Accuracy: {0}'.format(np.array(accuracies)))
            # logger.info('Acc Improvements (%): {0}'.format(np.array(accuracies)-np.array(ori_accs)))

            for i in range(len(id_dist)):
                data = {'selection_metric': metric, 'epochs': epochs, 'id_ratio': id_dist[i], 'budget': budget, 'original_acc': ori_accs[i], 'retrain_acc': accuracies[i], 'acc_improvement': accuracies[i]-ori_accs[i]}
                write_to_csv(log_path, data)

